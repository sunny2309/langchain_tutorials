{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b05a325",
   "metadata": {},
   "source": [
    "# Structured Data Extraction using LLMs (LangChain | LlaMa-3)\n",
    "\n",
    "## Different Approaches\n",
    "\n",
    "There are 3 broad approaches for information extraction using LLMs:\n",
    "\n",
    "* **Tool/Function Calling Mode:** Some LLMs support a tool or function calling mode. These LLMs can structure output according to a given schema. Generally, this approach is the easiest to work with and is expected to yield good results.\n",
    "\n",
    "* **JSON Mode:** Some LLMs are can be forced to output valid JSON. This is similar to tool/function Calling approach, except that the schema is provided as part of the prompt.\n",
    "\n",
    "* **Prompting Based:** LLMs that can follow instructions well can be instructed to generate text in a desired format. The generated text can be parsed downstream using existing Output Parsers or using custom parsers into a structured format like JSON. This approach can be used with LLMs that do not support JSON mode or tool/function calling modes. This approach is more broadly applicable, though may yield worse results than models that have been fine-tuned for extraction or function calling.\n",
    "\n",
    "In this tutorial, we have covered **JSON Mode** and **Prompting Based** approaches.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. **Load LLMs**\n",
    "2. **Define Schemas**\n",
    "3. **Generate Structured (Pydantic) Outputs**\n",
    "4. **Generate JSON Outputs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e24bdb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dotenv\n",
    "import os\n",
    "\n",
    "dotenv.load_dotenv(dotenv.find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a2db9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_api_key = os.environ['GROQ_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79137d6",
   "metadata": {},
   "source": [
    "## 1. Load LLMs\n",
    "\n",
    "* Login to **https://console.groq.com** and create API Key.\n",
    "\n",
    "### Groq Models\n",
    "\n",
    "* gemma-7b-it\n",
    "* llama3-70b-8192\n",
    "* llama3-8b-8192\n",
    "* mixtral-8x7b-32768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e2fd494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7f87abd62080>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7f87abd63790>, model_name='llama3-8b-8192', openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1', openai_proxy='')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llama3 = ChatOpenAI(api_key=groq_api_key, \n",
    "                    base_url=\"https://api.groq.com/openai/v1\",\n",
    "                    model=\"llama3-8b-8192\",\n",
    "                   )\n",
    "\n",
    "llama3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f8358d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm just an AI, so I don't have feelings or emotions like humans do. But I'm here to help you with any questions or tasks you may have! It's great to chat with you. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "ai_msg = llama3.invoke(\"Hi! How are you?\")\n",
    "\n",
    "print(ai_msg.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22ae3b9",
   "metadata": {},
   "source": [
    "## 2. Define Schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a2fb0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, List\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Class Representing Individual Person.\"\"\"\n",
    "\n",
    "    name: str = Field(description=\"Name of the person.\")\n",
    "    age: int = Field(description=\"Age of Person.\")\n",
    "    height: Optional[str] = Field(description=\"Height of Person\")\n",
    "\n",
    "class People(BaseModel):\n",
    "    \"\"\"Identifying information about all people in a text.\"\"\"\n",
    "\n",
    "    people: List[Person]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34c29cb",
   "metadata": {},
   "source": [
    "## 3. Generate Structured Outputs (Pydantic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d7af3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_llama3 = llama3.with_structured_output(Person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83812e23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7f87abd62080>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7f87abd63790>, model_name='llama3-8b-8192', openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1', openai_proxy=''), kwargs={'tools': [{'type': 'function', 'function': {'name': 'Person', 'description': 'Class Representing Individual Person.', 'parameters': {'type': 'object', 'properties': {'name': {'description': 'Name of the person.', 'type': 'string'}, 'age': {'description': 'Age of Person.', 'type': 'integer'}, 'height': {'description': 'Height of Person', 'type': 'string'}}, 'required': ['name', 'age']}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'Person'}}})\n",
       "| PydanticToolsParser(first_tool_only=True, tools=[<class '__main__.Person'>])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_llama3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac50bcce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Person(name='Anna', age=20, height=\"5'5\")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_llama3.invoke(\"Anna is 20 years old and five foot five inch.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e16a85cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_llama3 = llama3.with_structured_output(People)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5aab017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "People(people=[Person(name='Anna', age=20, height='5\\'5\"')])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_llama3.invoke(\"Anna is 20 years old and five foot five inch.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33c4b91c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "People(people=[Person(name='Anna', age=20, height='five foot five inch'), Person(name='Sam', age=25, height='five foot ten inch')])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_llama3.invoke(\"Anna is 20 years old and five foot five inch. Sam is 25 years old and 5 foot 10 inch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a13b49",
   "metadata": {},
   "source": [
    "## 4. Generate JSON Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c17b513a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Person',\n",
       " 'description': 'Class Representing Individual Person.',\n",
       " 'type': 'object',\n",
       " 'properties': {'name': {'title': 'Name',\n",
       "   'description': 'Name of the person.',\n",
       "   'type': 'string'},\n",
       "  'age': {'title': 'Age', 'description': 'Age of Person.', 'type': 'integer'},\n",
       "  'height': {'title': 'Height',\n",
       "   'description': 'Height of Person',\n",
       "   'type': 'string'}},\n",
       " 'required': ['name', 'age']}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Person.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5abdda73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import SimpleJsonOutputParser, JsonOutputParser\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are an expert data parser. Parse data from user query.\n",
    "\n",
    "Use this Schema:\n",
    "\n",
    "{schema}\n",
    "\n",
    "Respond only as JSON based on above-mentioned schema. Strictly follow JSON Schema and do not add extra fields.\n",
    "\n",
    "If you don't know any field then set it to None.\n",
    "\n",
    "{query}\n",
    "\"\"\")\n",
    "\n",
    "llm = prompt | llama3 | SimpleJsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a74bf295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Anna', 'age': 20, 'height': '5\\'5\"'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke({\"query\": \"Anna is 20 years old and five foot five inch.\", \n",
    "            \"schema\": Person.schema_json()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be7c9f5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'People',\n",
       " 'description': 'Identifying information about all people in a text.',\n",
       " 'type': 'object',\n",
       " 'properties': {'people': {'title': 'People',\n",
       "   'type': 'array',\n",
       "   'items': {'$ref': '#/definitions/Person'}}},\n",
       " 'required': ['people'],\n",
       " 'definitions': {'Person': {'title': 'Person',\n",
       "   'description': 'Class Representing Individual Person.',\n",
       "   'type': 'object',\n",
       "   'properties': {'name': {'title': 'Name',\n",
       "     'description': 'Name of the person.',\n",
       "     'type': 'string'},\n",
       "    'age': {'title': 'Age',\n",
       "     'description': 'Age of Person.',\n",
       "     'type': 'integer'},\n",
       "    'height': {'title': 'Height',\n",
       "     'description': 'Height of Person',\n",
       "     'type': 'string'}},\n",
       "   'required': ['name', 'age']}}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "People.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2abc194e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'people': [{'name': 'Anna', 'age': 20, 'height': 'five foot five inch'}]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke({\"query\": \"Anna is 20 years old and five foot five inch.\",\n",
    "            \"schema\": People.schema_json()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "990407c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'people': [{'name': 'Anna', 'age': 20, 'height': 'five foot five inch'},\n",
       "  {'name': 'Sam', 'age': 25, 'height': '5 foot 10 inch'}]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke({\"query\": \"Anna is 20 years old and five foot five inch. Sam is 25 years old and 5 foot 10 inch.\",\n",
    "            \"schema\": People.schema_json()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "43c89fc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'people': [{'name': 'Anna', 'age': 20, 'height': '5\\'5\"'},\n",
       "  {'name': 'Sam', 'age': 25, 'height': '5\\'10\"'},\n",
       "  {'name': 'Donna', 'age': 35, 'height': '5\\'8\"'},\n",
       "  {'name': 'Jack', 'age': 45, 'height': '6\\'2\"'},\n",
       "  {'name': 'Elon', 'age': 55, 'height': '6\\'0\"'}]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "Anna is 20 years old and five foot five inch. She lives in UK. Currently, she is working as marketing manager.\n",
    "\n",
    "Sam is 25 years old and 5 foot 10 inch. He lives in US. Currently, he is working as product manager at JP Morgan.\n",
    "\n",
    "Donna is 35 years old and 5 foot 8 inch. She lives in Singapore. Currently, she is working as developer advocate.\n",
    "\n",
    "Jack is 45 years old and 6 foot 2 inch. He lives in Germany. Currently, He is CEO at Skype.\n",
    "\n",
    "Elon is 55 years old and 6 foot tall. He lives in US. Currently, He is CEO of Tesla.\n",
    "\"\"\"\n",
    "\n",
    "llm.invoke({\"query\": query, \"schema\": People.schema_json()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2ba0095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the parsed data in JSON format based on the provided schema:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"people\": [\n",
      "    {\n",
      "      \"name\": \"Anna\",\n",
      "      \"age\": 20,\n",
      "      \"height\": \"5'5\\\"\",\n",
      "      \"description\": \"Marketing Manager\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Sam\",\n",
      "      \"age\": 25,\n",
      "      \"height\": \"5'10\\\"\",\n",
      "      \"description\": \"Product Manager at JP Morgan\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Donna\",\n",
      "      \"age\": 35,\n",
      "      \"height\": \"5'8\\\"\",\n",
      "      \"description\": \"Developer Advocate\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Jack\",\n",
      "      \"age\": 45,\n",
      "      \"height\": \"6'2\\\"\",\n",
      "      \"description\": \"CEO at Skype\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Elon\",\n",
      "      \"age\": 55,\n",
      "      \"height\": \"6'0\\\"\",\n",
      "      \"description\": \"CEO of Tesla\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "Note that I've followed the schema's requirements and only included the required fields. I've also set any unknown fields to `None` as per the schema.\n"
     ]
    }
   ],
   "source": [
    "ai_msg = (prompt | llama3).invoke({\"query\": query, \"schema\": People.schema_json()})\n",
    "\n",
    "print(ai_msg.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4950116f",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this video, I explained how to extract **Structured Data** from text using **open source  LLMs**. For coding, we used LLM framework **langchain**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
