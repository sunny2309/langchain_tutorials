{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4eaff13",
   "metadata": {},
   "source": [
    "# Function Calling with Open Source LLMs (LLaMa-3, LangChain & Groq API)\n",
    "\n",
    "### Table of Content\n",
    "\n",
    "1. **Load LLMs**\n",
    "2. **Define Tools**\n",
    "3. **Link Tools with LLMs**\n",
    "4. **Use LLM with Tools**\n",
    "5. **Create Independent Decision Taking Agent**\n",
    "\n",
    "### Installation\n",
    "\n",
    "* **pip install langchain**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7520c82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import os\n",
    "\n",
    "dotenv.load_dotenv(dotenv.find_dotenv())\n",
    "\n",
    "groq_api_key = os.environ[\"GROQ_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c80509f",
   "metadata": {},
   "source": [
    "## 1. Load LLMs\n",
    "\n",
    "* Login to **https://console.groq.com** and create API Key.\n",
    "\n",
    "### Groq Models\n",
    "\n",
    "ID|\tREQUESTS PER MINUTE|\tREQUESTS PER DAY|\tTOKENS PER MINUTE\n",
    "-|-|-|-\n",
    "llama3-70b-8192\t|30\t|14,400\t|6,000\n",
    "llama3-8b-8192\t|30\t|14,400\t|30,000\n",
    "gemma-7b-it\t|30\t|14,400\t|15,000\n",
    "mixtral-8x7b-32768\t|30\t|14,400\t|5,000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb4f009e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7f89d749dd80>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7f89d749f490>, model_name='llama3-8b-8192', openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1', openai_proxy='')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llama3 = ChatOpenAI(api_key=groq_api_key, \n",
    "                    base_url=\"https://api.groq.com/openai/v1\",\n",
    "                    model=\"llama3-8b-8192\",\n",
    "                   )\n",
    "\n",
    "llama3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e36c9b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm just an AI, I don't have emotions or personal experiences like humans do, so I don't have feelings or emotions. I exist solely to provide information, answer questions, and assist with tasks to the best of my ability. I'm here to help you with any questions or topics you'd like to discuss, so feel free to ask me anything!\n"
     ]
    }
   ],
   "source": [
    "ai_msg = llama3.invoke(\"Hi! How are you?\")\n",
    "\n",
    "print(ai_msg.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc663a6",
   "metadata": {},
   "source": [
    "## 2. Define Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cef1336",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiplies a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "tools = [add, multiply]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5481569d",
   "metadata": {},
   "source": [
    "## 3. Link Tools with LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37e5a97d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'add', 'args': {'a': 121, 'b': 5}, 'id': 'call_srwq'},\n",
       " {'name': 'multiply', 'args': {'a': 110, 'b': 9}, 'id': 'call_k7tr'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama3_with_tools = llama3.bind_tools(tools) # tool_choice = 'any', 'actual_tool_name', \n",
    "\n",
    "ai_msg = llama3_with_tools.invoke(\"What is (121+5)*9 ?\")\n",
    "\n",
    "ai_msg.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80c8aae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'function',\n",
       "  'function': {'name': 'add',\n",
       "   'description': 'add(a: int, b: int) -> int - Adds a and b.\\n\\n    Args:\\n        a: first int\\n        b: second int',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'a': {'type': 'integer'}, 'b': {'type': 'integer'}},\n",
       "    'required': ['a', 'b']}}},\n",
       " {'type': 'function',\n",
       "  'function': {'name': 'multiply',\n",
       "   'description': 'multiply(a: int, b: int) -> int - Multiplies a and b.\\n\\n    Args:\\n        a: first int\\n        b: second int',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'a': {'type': 'integer'}, 'b': {'type': 'integer'}},\n",
       "    'required': ['a', 'b']}}}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama3_with_tools.to_json()['kwargs']['kwargs']['tools']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee5d835",
   "metadata": {},
   "source": [
    "## 4. Use LLM with Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eaf292b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is (121+5)*9 ?'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_bpvw', 'function': {'arguments': '{\"a\":121,\"b\":5}', 'name': 'add'}, 'type': 'function'}, {'id': 'call_kskt', 'function': {'arguments': '{\"a\":126,\"b\":9}', 'name': 'multiply'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 124, 'prompt_tokens': 1104, 'total_tokens': 1228, 'prompt_time': 0.859129764, 'completion_time': 0.132251627, 'total_time': 0.991381391}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_a97cfe35ae', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-a819a429-7c31-4bff-8721-4de91c130431-0', tool_calls=[{'name': 'add', 'args': {'a': 121, 'b': 5}, 'id': 'call_bpvw'}, {'name': 'multiply', 'args': {'a': 126, 'b': 9}, 'id': 'call_kskt'}]),\n",
       " ToolMessage(content='126', tool_call_id='call_bpvw'),\n",
       " ToolMessage(content='1134', tool_call_id='call_kskt')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, ToolMessage\n",
    "\n",
    "query = \"What is (121+5)*9 ?\"\n",
    "\n",
    "messages = [HumanMessage(query)]\n",
    "ai_msg = llama3_with_tools.invoke(query)\n",
    "messages.append(ai_msg)\n",
    "\n",
    "for tool_call in ai_msg.tool_calls:\n",
    "    selected_tool = {\"add\": add, \"multiply\": multiply}[tool_call[\"name\"].lower()]\n",
    "    tool_output = selected_tool.invoke(tool_call[\"args\"])\n",
    "    messages.append(ToolMessage(tool_output, tool_call_id=tool_call[\"id\"]))\n",
    "\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5dae973d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now that we have the results of both tool calls, we can calculate the final answer.\n",
      "\n",
      "The first tool call \"call_bpvw\" yielded 126.\n",
      "\n",
      "The second tool call \"call_kskt\" yielded 1134.\n",
      "\n",
      "To calculate the final answer, we multiply 126 by 9, which is the input for the second tool call.\n",
      "\n",
      "126 * 9 = 1134\n",
      "\n",
      "So, the final answer is indeed 1134.\n"
     ]
    }
   ],
   "source": [
    "final_response = llama3.invoke(messages)\n",
    "\n",
    "print(final_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "34fc8e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1134"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(121+5)*9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605e404c",
   "metadata": {},
   "source": [
    "## 5. Create Independent Decision Taking Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fecd5f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_tool_calling_agent, create_openai_tools_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. You may not need to use tools for every query - the user may just want to chat!\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "llama3 = ChatOpenAI(api_key=groq_api_key,\n",
    "                    base_url=\"https://api.groq.com/openai/v1/\", \n",
    "                    model=\"llama3-70b-8192\",\n",
    "                    temperature=0.0\n",
    "                   )\n",
    "\n",
    "agent = create_tool_calling_agent(llama3, tools, prompt)\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bd44abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `add` with `{'a': 199, 'b': 8}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m207\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `multiply` with `{'a': 207, 'b': 4}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m828\u001b[0m\u001b[32;1m\u001b[1;3mThe final answer is 828.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Add 8 to 199 and then multiply by 4')],\n",
       " 'output': 'The final answer is 828.'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "agent_executor.invoke({\"messages\": [HumanMessage(content=\"Add 8 to 199 and then multiply by 4\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5a793e30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "828"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(8+199)*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8467d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `multiply` with `{'a': 3, 'b': 12}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m36\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `add` with `{'a': 11, 'b': 49}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m60\u001b[0m\u001b[32;1m\u001b[1;3mThe answers are 36 and 60.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What is 3 * 12? Also, what is 11 + 49?')],\n",
       " 'output': 'The answers are 36 and 60.'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"messages\": [HumanMessage(content=\"What is 3 * 12? Also, what is 11 + 49?\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5e4abfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `add` with `{'a': 121, 'b': 5}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m126\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `multiply` with `{'a': 126, 'b': 2}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m252\u001b[0m\u001b[32;1m\u001b[1;3mThe final answer is 252.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Add 121 to 5 then multiply result by 2')],\n",
       " 'output': 'The final answer is 252.'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"messages\": [HumanMessage(content=\"Add 121 to 5 then multiply result by 2\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05ad3390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "252"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(121+5) * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6148e32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `add` with `{'a': 121323445, 'b': 453341321}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m574664766\u001b[0m\u001b[32;1m\u001b[1;3mThe result is 574664766.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Add 121,323,445 to 453,341,321')],\n",
       " 'output': 'The result is 574664766.'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"messages\": [HumanMessage(content=\"Add 121,323,445 to 453,341,321\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72917673",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'574,664,766'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{121323445+453341321:,}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fab471aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `add` with `{'a': 2, 'b': 121}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m123\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `multiply` with `{'a': 123, 'b': 5}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m615\u001b[0m\u001b[32;1m\u001b[1;3mThe final answer is 615.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Add two to one hundred twenty one and then multiply result by five')],\n",
       " 'output': 'The final answer is 615.'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"messages\": [HumanMessage(content=\"Add two to one hundred twenty one and then multiply result by five\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a42c110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "615"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2+121) *5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c98ef6",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, I explained how to pass **functions** to **open source LLMs**. We used **Groq API** for accessing open source LLM **LLaMa-3**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
